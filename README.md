# Claude Context Extender

A fun tool that enables Claude to work effectively with documents that exceed its context window size.

## ğŸ“– Overview

Claude Context Extender is a Node.js application that enhances Claude's ability to process and answer questions about large documents by using an iterative approach. It intelligently splits documents into manageable chunks, creates an index for efficient retrieval, and processes relevant sections sequentially to produce comprehensive answers.

The tool implements an advanced Retrieval-Augmented Generation (RAG) approach that overcomes the context window limitations of large language models.

## âœ¨ Key Features

- **Smart Chunking**: Automatically breaks documents into optimal segments with configurable overlap
- **Efficient Indexing**: Creates compact but effective indexes with summaries and keywords for each chunk
- **Semantic Search**: Uses Claude to identify the most relevant chunks for a query
- **Iterative Processing**: Processes one chunk at a time to handle documents of any size
- **Progressive Answer Building**: Continuously refines answers as more information is processed
- **Conversation Management**: Maintains conversation history with automatic summarization
- **Rate Limiting**: Intelligently manages API request timing to prevent rate limit errors

## ğŸ› ï¸ Installation

### Prerequisites

- Node.js (v14 or later)
- An Anthropic API key for Claude

### Steps

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/claude-context-extender.git
   cd claude-context-extender
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Create configuration files:
   ```bash
   cp .env.example .env
   # Edit .env and add your Claude API key
   ```

4. Make the CLI executable:
   ```bash
   chmod +x bin/cli.js
   ```

5. Run the setup script:
   ```bash
   npm run setup
   ```

## ğŸ“ Usage

### Creating an Index

```bash
# Index a single file
node bin/cli.js index path/to/document.pdf --name "My Document"

# Index a directory of documents
node bin/cli.js index path/to/documents/ --name "My Collection"
```

### Querying an Index

```bash
# Query an index by ID
node bin/cli.js query your-index-id -q "What is the main thesis of this document?"

# Interactive query mode
node bin/cli.js query your-index-id
```

### Managing Indexes

```bash
# List all indexes
node bin/cli.js list

# View details about a specific index
node bin/cli.js info your-index-id

# Delete an index
node bin/cli.js delete your-index-id
```

### Managing Conversations

```bash
# List all conversations
node bin/cli.js conversations

# View details about a specific conversation
node bin/cli.js conversation-info your-conversation-id

# Delete a conversation
node bin/cli.js delete-conversation your-conversation-id
```

### Configuration

```bash
# View current configuration
node bin/cli.js config --view

# Update configuration
node bin/cli.js config --update
```

## âš™ï¸ Configuration Options

The system can be customized through the `config/default.json` file:

| Category    | Option                     | Description                                      | Default  |
|-------------|----------------------------|--------------------------------------------------|----------|
| claude      | model                      | Claude model to use                              | claude-3-5-haiku-20241022 |
| claude      | maxTokens                  | Maximum context window size                      | 100000   |
| claude      | tokenRatePerMinute         | Rate limit for tokens per minute                 | 50000    |
| chunking    | chunkSizePercentage        | Size of each chunk relative to context window    | 40%      |
| chunking    | overlapPercentage          | Overlap between chunks                           | 10%      |
| query       | maxChunksPerQuery          | Maximum chunks to process per query              | 5        |
| conversation| maxRecentExchanges         | Recent exchanges to keep in full                 | 5        |
| conversation| mergeFrequency             | Frequency of merging old conversation history    | 3        |

## ğŸ—ï¸ Project Structure

```
claude-context-extender/
â”œâ”€â”€ bin/                      # CLI scripts
â”‚   â””â”€â”€ cli.js                # Main CLI entry point
â”‚
â”œâ”€â”€ config/                   # Configuration files
â”‚   â””â”€â”€ default.json          # Default configuration
â”‚
â”œâ”€â”€ data/                     # Data storage
â”‚   â”œâ”€â”€ indexes/              # Stored indexes
â”‚   â””â”€â”€ conversations/        # Stored conversations
â”‚
â”œâ”€â”€ scripts/                  # Utility scripts
â”‚   â”œâ”€â”€ install.js            # Installation script
â”‚   â””â”€â”€ organize-files.js     # Project structure script
â”‚
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ app.js                # Main application entry point
â”‚   â”œâ”€â”€ controllers/          # Application controllers
â”‚   â”œâ”€â”€ services/             # Core services
â”‚   â”‚   â”œâ”€â”€ FileProcessor.js  # File reading and chunking
â”‚   â”‚   â”œâ”€â”€ IndexManager.js   # Index management
â”‚   â”‚   â”œâ”€â”€ ClaudeClient.js   # Claude API client
â”‚   â”‚   â””â”€â”€ IterativeAnswerer.js # Iterative answer generation
â”‚   â”œâ”€â”€ cli/                  # CLI implementation
â”‚   â”œâ”€â”€ utils/                # Utility modules
â”‚   â””â”€â”€ models/               # Data models
â”‚
â”œâ”€â”€ .env.example              # Example environment variables
â”œâ”€â”€ package.json              # Project metadata and dependencies
â””â”€â”€ README.md                 # Project documentation
```

## ğŸš€ How It Works

1. **Document Processing**:
   - Documents are split into chunks of manageable size
   - Each chunk is processed to create summaries and keywords
   - A searchable index is built from these chunks

2. **Query Handling**:
   - When a question is asked, the system finds the most relevant chunks
   - The chunks are processed one by one in order of relevance
   - With each chunk, the answer is progressively built and refined
   - A final summarization step ensures the answer is coherent and complete

3. **Conversation Management**:
   - The system tracks conversation history
   - Recent exchanges are kept in full
   - Older exchanges are merged into a summary to save space
   - This enables unlimited conversation length

## ğŸ”„ Comparison with Traditional RAG

Our simple approach enhances traditional RAG (Retrieval-Augmented Generation) in several ways:

1. **Iterative Processing**: Instead of passing all relevant chunks at once (which can exceed the context window), we process them sequentially.

2. **Progressive Refinement**: The answer is built step by step, with each new chunk potentially adding or correcting information.

3. **Working Memory**: The system maintains a "working memory" of the current answer as it processes more information.

4. **Unlimited Document Size**: By processing chunks sequentially, the system can handle documents of any size.

5. **Conversation Continuity**: The conversation history management allows for ongoing interactions about large documents.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgements

- Anthropic for the Claude API
- My mom, who always had faith in me

---

Built with â¤ï¸ for educational purposes capabilities.